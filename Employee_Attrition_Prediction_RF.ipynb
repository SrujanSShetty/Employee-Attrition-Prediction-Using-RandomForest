{"cells":[{"cell_type":"markdown","metadata":{},"source":["# üß† Employee Attrition Prediction Using Random Forest\n","This notebook walks through a complete machine learning pipeline to predict employee attrition using IBM HR data. The goal is to identify which employees are likely to leave and understand why, using Random Forest‚Äîa powerful, interpretable ensemble model.\n"]},{"cell_type":"markdown","metadata":{},"source":["## üìå Step 1: Import Libraries\n","We'll use standard Python libraries for data analysis, modeling, and visualization."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"markdown","metadata":{},"source":["## üìÅ Step 2: Load and Explore the Dataset\n","The dataset contains information on current and former employees and whether they left the company (`Attrition`)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition 2.csv\")\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## üîç Step 3: Data Cleaning and Preprocessing\n","- Dropping constant or ID columns: `EmployeeNumber`, `EmployeeCount`, `Over18`, `StandardHours`\n","- Encoding the `Attrition` column to binary (Yes=1, No=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.drop(columns=['EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours'], inplace=True)\n","df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})"]},{"cell_type":"markdown","metadata":{},"source":["## üß† Step 4: One-Hot Encode Categorical Variables\n","We use `pd.get_dummies()` to convert categorical variables into numerical format required by the model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["categorical_cols = df.select_dtypes(include='object').columns\n","df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"]},{"cell_type":"markdown","metadata":{},"source":["## üéØ Step 5: Split Features and Target\n","- `X` contains all features\n","- `y` is the target variable (`Attrition`)\n","- Split into training and testing sets (80/20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df_encoded.drop('Attrition', axis=1)\n","y = df_encoded['Attrition']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["## üå≥ Step 6: Train Random Forest Model\n","**Why Random Forest?**\n","- Handles both numerical and categorical data well\n","- Reduces overfitting with ensemble of decision trees\n","- Gives feature importance for interpretation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["## üß™ Step 7: Evaluate Model Performance\n","- **Accuracy**: Overall correctness\n","- **Precision**: Correct 'Yes' predictions out of all predicted 'Yes'\n","- **Recall**: Correct 'Yes' predictions out of all actual 'Yes'\n","- **F1-Score**: Harmonic mean of Precision & Recall"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = rf_model.predict(X_test)\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["## üìä Step 8: Feature Importance\n","**Why?**\n","- Understand which features impact attrition most\n","- Provide actionable insights to HR\n","- Helps in feature selection for future models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["importances = rf_model.feature_importances_\n","feature_names = X.columns\n","feat_importance = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n","\n","plt.figure(figsize=(10, 6))\n","feat_importance.head(10).plot(kind='barh', color='teal')\n","plt.gca().invert_yaxis()\n","plt.title(\"Top 10 Important Features for Predicting Attrition\")\n","plt.xlabel(\"Feature Importance\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## ‚úÖ Conclusion & Next Steps\n","**Key Findings:**\n","- `MonthlyIncome`, `OverTime`, `Age`, and `TotalWorkingYears` are strong predictors.\n","- Random Forest gave ~84% accuracy with balanced precision and recall.\n","\n","**Next Steps:**\n","- Use SHAP for deeper model explainability\n","- Try other models like XGBoost, LightGBM\n","- Deploy as a dashboard using Flask or Streamlit"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10"}},"nbformat":4,"nbformat_minor":5}
